{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Help BOBAI: Classify an unknown language #2\n",
        "\n",
        "You know the drill.\n",
        "Your task is to build the best text classifier for language X that you can, while operating within the constraints of Bobai:\n",
        "\n",
        "*   The classifier has to be based on mBERT (and cannot use any additional pre-trained language encoder).\n",
        "*   The classifier has to train in under 8 hours using an L4 GPU as the compute resources of the company are limited.\n",
        "*   The classifier has to perform inference on any random 500 data samples in under 5 minutes (Bobai will then apply their optimization tricks to bring this time even further down).\n",
        "*   You can spend as much time as you want trying to decrypt the data\n",
        "*   The given code is the code you received for the at-home assignment with updated links. You can modify whatever you deem necessarry"
      ],
      "metadata": {
        "id": "Hu6t1bXlk1tO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n"
      ],
      "metadata": {
        "id": "J6BNTewtA-Ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HuggingFace configuration\n",
        "\n",
        "The steps below need to be completed by the team leader:\n",
        "\n",
        "1. Create a team account on [HuggingFace](https://huggingface.co/) using the Gmail account provided by the IOAI organizers.\n",
        "\n",
        "2. Go to the [Olimpiada-AI HuggingFace repo](https://huggingface.co/Olimpiada-AI) to access the datasets.\n",
        "\n",
        "3. In settings, create two Access Tokens, one with read rights, one with write rights, and store those in [Colab Secrets](https://www.youtube.com/watch?v=q87i2LZbbPc) as `hf_read` and `hf_write`, respectively."
      ],
      "metadata": {
        "id": "0Tg2sPb2ELb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "read_access_token = userdata.get('hf_read')\n",
        "write_access_token = userdata.get('hf_write')"
      ],
      "metadata": {
        "id": "sV85hgL0yxn0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies"
      ],
      "metadata": {
        "id": "SyLH6A-YEJG3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import importlib\n",
        "import torch, transformers\n",
        "\n",
        "if '2.3.0' not in torch.__version__:\n",
        "  !pip install torch==2.3.0\n",
        "if transformers.__version__!='4.41.2':\n",
        "  !pip install transformers==4.41.2\n",
        "\n",
        "if importlib.util.find_spec('datasets') is None:\n",
        "  !pip install datasets==2.18.0s\n",
        "  !pip install evaluate==0.4.2\n",
        "  !pip install accelerate -U\n"
      ],
      "metadata": {
        "id": "8VH0WJYuM_4Z",
        "collapsed": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you've just installed `accelerate`, execute `Runtime > Restart session and run all` in the Colab UI menu above."
      ],
      "metadata": {
        "id": "zridt_PWpd9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "EFTIQ9tDMqsE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "\n",
        "classification_dataset = load_dataset('Olimpiada-AI/NLP_problem', token=read_access_token)"
      ],
      "metadata": {
        "id": "CpgcmI2NMLyF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline"
      ],
      "metadata": {
        "id": "cv9MBElmMs6G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the pre-trained tokenizer and use it to process the data\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-multilingual-uncased\")\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)\n",
        "\n",
        "tokenized_data = classification_dataset.map(preprocess_function, batched=True)\n",
        "\n",
        "# Extract the dataset to split\n",
        "full_train_dataset = tokenized_data['train']\n",
        "\n",
        "# Convert to Pandas DataFrame for splitting\n",
        "import pandas as pd\n",
        "df = full_train_dataset.to_pandas()\n",
        "\n",
        "# Split the dataset into train and test sets\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'])  # Adjust test_size as needed\n",
        "\n",
        "# Convert back to Dataset\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Create a new DatasetDict\n",
        "split_tokenized_data = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "tSOWNJRKNoWM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the evaluation metric\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "\n",
        "f1 = evaluate.load(\"f1\")\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return f1.compute(predictions=predictions, references=labels, average='macro')"
      ],
      "metadata": {
        "id": "nN64VrhSNuYA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model and the training configuration\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"google-bert/bert-base-multilingual-uncased\", num_labels=5\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"baseline_bobai_2\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=64,\n",
        "    per_device_eval_batch_size=64,\n",
        "    num_train_epochs=20,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    save_total_limit=5,\n",
        "    metric_for_best_model='f1',\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=True,\n",
        "    hub_strategy=\"checkpoint\",\n",
        "    hub_token=write_access_token,\n",
        "    hub_private_repo=True,\n",
        "    hub_model_id='baseline_bobai_2'\n",
        "\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=split_tokenized_data[\"train\"],\n",
        "    eval_dataset=split_tokenized_data[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "hCojWe8hOgRv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6fd61f0-d66a-4755-9664-156b8218d8e3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-multilingual-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(split_tokenized_data)"
      ],
      "metadata": {
        "id": "5rFMXscHXDqI",
        "outputId": "a45fd7ff-fd77-481b-ba30-eb36d0bbff31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', '__index_level_0__'],\n",
            "        num_rows: 2589\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask', '__index_level_0__'],\n",
            "        num_rows: 648\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# execute the model training\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "VTJ-w6BnosYy",
        "outputId": "76952c1d-3d91-4bb1-9316-db5cfe473208",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='820' max='820' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [820/820 32:19, Epoch 20/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.558474</td>\n",
              "      <td>0.278640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.445435</td>\n",
              "      <td>0.340132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.408473</td>\n",
              "      <td>0.355641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.411950</td>\n",
              "      <td>0.363624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.290221</td>\n",
              "      <td>0.464859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.258511</td>\n",
              "      <td>0.468592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.204345</td>\n",
              "      <td>0.513798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.158278</td>\n",
              "      <td>0.530088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.158539</td>\n",
              "      <td>0.512119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.127043</td>\n",
              "      <td>0.549813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.113716</td>\n",
              "      <td>0.559747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.076729</td>\n",
              "      <td>0.596650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.084600</td>\n",
              "      <td>1.094447</td>\n",
              "      <td>0.589794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.084600</td>\n",
              "      <td>1.073146</td>\n",
              "      <td>0.614474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.084600</td>\n",
              "      <td>1.036870</td>\n",
              "      <td>0.623587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.084600</td>\n",
              "      <td>1.002149</td>\n",
              "      <td>0.642138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.084600</td>\n",
              "      <td>1.013984</td>\n",
              "      <td>0.645074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.084600</td>\n",
              "      <td>1.023770</td>\n",
              "      <td>0.645361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.084600</td>\n",
              "      <td>0.999722</td>\n",
              "      <td>0.644803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.084600</td>\n",
              "      <td>0.997607</td>\n",
              "      <td>0.653884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=820, training_loss=0.8548285507574314, metrics={'train_runtime': 1941.0752, 'train_samples_per_second': 26.676, 'train_steps_per_second': 0.422, 'total_flos': 3758033176588548.0, 'train_loss': 0.8548285507574314, 'epoch': 20.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "oSYydzx9NAGU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run the trained model on a dev/test split\n",
        "data_split = \"dev\"\n",
        "eval_out = trainer.predict(tokenized_data[data_split])\n",
        "predictions = eval_out.predictions.argmax(1)\n",
        "labels = eval_out.label_ids\n",
        "dev_f1 = f1.compute(predictions=predictions, references=labels, average='macro')"
      ],
      "metadata": {
        "id": "jaa80VhiNBG_",
        "outputId": "01248b2b-afc6-447b-aa9d-cdc16eb248a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'dev'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-3a6149854adc>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run the trained model on a dev/test split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0meval_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/datasets/dataset_dict.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNamedSplit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             available_suggested_splits = [\n",
            "\u001b[0;31mKeyError\u001b[0m: 'dev'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "dwT-GexR956j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# UPDATE THIS CELL ACCORDINGLY\n",
        "\n",
        "# define a funciton to load your tokenizer and model from a HF path\n",
        "# the path variables can be strings or lists of strings (for ensemble solutions)\n",
        "def load_model(path_to_tokenizer, path_to_model, token):\n",
        "  # Example:\n",
        "  tokenizer = AutoTokenizer.from_pretrained(path_to_tokenizer, token=token)\n",
        "  model = AutoModelForSequenceClassification.from_pretrained(path_to_model, token=token)\n",
        "  model.eval()\n",
        "\n",
        "  return tokenizer, model\n",
        "\n",
        "# define a \"predict\" function that takes the model and a list of input strings\n",
        "# and returns the outputs as a list of integer classes\n",
        "def predict(tokenizer, model, input_texts):\n",
        "  #Example:\n",
        "  predictions = []\n",
        "  for input_text in input_texts:\n",
        "\n",
        "    input_ids = tokenizer(input_text, return_tensors=\"pt\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "      logits = model(**input_ids).logits\n",
        "\n",
        "    predictions.append(logits.argmax().item())\n",
        "\n",
        "  return predictions\n",
        "\n",
        "# set variables\n",
        "path_to_model = \"path/to/your/best/model/on/hf\" # can be a list instead\n",
        "path_to_tokenizer = \"path/to/your/best/tokenizer/on/hf\" # can be a list instead\n",
        "model_access_token = \"access token\" # a fine-grained token with read rights for your model repository\n"
      ],
      "metadata": {
        "id": "oZkqwv229-PM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DO NOT CHANGE THIS CELL!!!\n",
        "\n",
        "tokenizer, model = load_model(path_to_tokenizer, path_to_model, token=model_access_token)\n",
        "\n",
        "test_data = load_dataset(\"Olimpiada-AI/NLP_problem_test\")['test']['text']\n",
        "\n",
        "predictions = predict(tokenizer, model, test_data)\n",
        "\n",
        "with open('test_predictions.txt', 'w') as outfile:\n",
        "  outfile.write('\\n'.join([str(p) for p in predictions]))"
      ],
      "metadata": {
        "id": "68SDwUjRLBYC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}